# model: deepseek:deepseek-chat
model: openrouter:anthropic/claude-3.7-sonnet:floor
keybindings: vi
function_calling: true
stream: true
save: true
wrap: auto
wrap_code: true
save_shell_history: true
compress_threshold: 256000
save_session: true
# Text prompt used for creating a concise summary of session message
summarize_prompt: '<system>This conversation became quite long and we will run out of context. Please summarize this discussion to use as info for a future prompt. Include relevant information to help you continue the conversation.</system>'
# Text prompt used for including the summary of the entire session
summary_prompt: '<system>This is a summary of the previous conversation. It was cut off because it got too long. This is the summary. Please continue the conversation. If you have questions, feel free to ask!</system>'

clients:
  - type: openai-compatible
    name: zhipu
    api_base: https://open.bigmodel.cn/api/coding/paas/v4
    api_key: @ZHIPU_API_KEY@
    models:
      - name: glm-4.5-air-non-reasoning
        real_name: glm-4.5-Air
        patch:
          body:
            thinking:
              type: "disabled"
      - name: glm-4.6
        real_name: glm-4.6

  - type: openai-compatible
    name: openrouter
    api_base: https://openrouter.ai/api/v1
    api_key: @OPENROUTER_API_KEY@
    models:
      - name: grok-4-fast-non-reasoning
        real_name: x-ai/grok-4-fast
        patch:
          body:
            reasoning:
              enabled: false
      - name: grok-code-fast-non-reasoning
        real_name: x-ai/grok-code-fast-1
        patch:
          body:
            reasoning:
              enabled: false

      - name: glm-4.5-air-non-reasoning
        real_name: z-ai/glm-4.5-air
        patch:
          body:
            reasoning:
              enabled: false


  - type: openai-compatible
    name: deepseek
    api_base: https://api.deepseek.com/v1
    api_key: @DEEPSEEK_API_KEY@
    models:
      - name: deepseek-chat
        max_input_tokens: 64000
        supports_vision: true
        supports_function_calling: true

      - name: deepseek-reasoner
        max_input_tokens: 64000
        supports_vision: true
        supports_function_calling: true
